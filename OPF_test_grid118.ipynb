{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junfeiai/Info_CcGAN_OPF/blob/main/OPF_test_grid118.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3b0S3pfpf3B"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import backend as K\n",
        "from matplotlib import pyplot as plt\n",
        "import sys\n",
        "import pandas as pd\n",
        "from pandas import DataFrame as df\n",
        "from numpy.random import randn\n",
        "from scipy.io import loadmat\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.models import load_model,Sequential,Model\n",
        "import math\n",
        "import time\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D,Lambda,Concatenate\n",
        "import pdb; \n",
        "import scipy\n",
        "from keras.constraints import Constraint\n",
        "import datetime\n",
        "from scipy.stats import weibull_min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yleLoEj3qgw3"
      },
      "outputs": [],
      "source": [
        "mat_load = loadmat('IEEE118_load.mat')\n",
        "opf_condition = loadmat('grid118_fc_new_test_conditions_by_opf.mat')['conditions_list']\n",
        "opf_points = loadmat('grid118_fc_new_test_points_by_opf.mat')['datapoints_list']\n",
        "mat_y = loadmat('Y_bus118.mat')\n",
        "mat_gen = loadmat('IEEE118_gen.mat')['gen118']\n",
        "mat_gencost = loadmat('case118_gencost.mat')['gencost']\n",
        "Y_bus = mat_y['Y_bus118'].toarray().astype('complex64')\n",
        "gen_ids=mat_gen[:,0]-1\n",
        "baseMVA = 100\n",
        "case118_pload = mat_load['aa'][:,2]/baseMVA\n",
        "case118_qload = mat_load['aa'][:,3]/baseMVA\n",
        "opf_real_conditions = opf_condition[:]/baseMVA\n",
        "opf_real_vm= opf_points[:,0:118]\n",
        "opf_real_va = opf_points[:,118:118*2]\n",
        "opf_matpower_pq = opf_points[:,118*2:]\n",
        "opf_matpower_p = opf_points[:,236:290]\n",
        "opf_matpower_q = opf_points[:,290:]\n",
        "opf_real_p = np.zeros([opf_points.shape[0],118])\n",
        "opf_real_q = np.zeros([opf_points.shape[0],118])\n",
        "j=0\n",
        "for i in range(0,118):\n",
        "  if i in gen_ids:\n",
        "    opf_real_p[:,i]=opf_matpower_p[:,j]\n",
        "    opf_real_q[:,i]=opf_matpower_q[:,j]\n",
        "    j=j+1\n",
        "opf_real_p=opf_real_p/baseMVA\n",
        "opf_real_q=opf_real_q/baseMVA\n",
        "\n",
        "gen_id=mat_gen[:,0]-1\n",
        "non_gen_ids = np.zeros([64])\n",
        "j=0\n",
        "for i in range(0,118):\n",
        "  if i not in gen_id:\n",
        "    non_gen_ids[j]=i\n",
        "    j=j+1\n",
        "wind_der_ids = non_gen_ids[:-40]\n",
        "solar_der_ids = non_gen_ids[-40:]\n",
        "\n",
        "basis_vector = np.zeros(118)\n",
        "for i in range(0,118):\n",
        "  if i in gen_ids:\n",
        "    basis_vector[i]=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-cvw0RoPQoh"
      },
      "outputs": [],
      "source": [
        "def get_gencost(number_of_buses,mat_gen,mat_gencost):\n",
        "  \"\"\"\n",
        "  Function to format financial cost efficients in MatPower \n",
        "  to a tensor.\n",
        "  :number_of_buses: determins the dimension of the tensor\n",
        "  :mat_gen: generator list in MatPower\n",
        "  :mat_gencost: generator cost in MatPower\n",
        "  :return: tf_c1,tf_c2 are the first and second order coefficient tensors\n",
        "  \"\"\" \n",
        "  gen_ids = mat_gen[:,0]-1\n",
        "  c1=np.zeros(number_of_buses)\n",
        "  c2=np.zeros(number_of_buses)\n",
        "  j=0\n",
        "  for i in range(0,number_of_buses):\n",
        "    if i in gen_ids:\n",
        "      c1[i] = mat_gencost[j,5]\n",
        "      c2[i] = mat_gencost[j,4]\n",
        "      j=j+1\n",
        "  tf_c1 = tf.convert_to_tensor(c1,dtype='float32')\n",
        "  tf_c2 = tf.convert_to_tensor(c2,dtype='float32')\n",
        "  return tf_c1,tf_c2\n",
        "\n",
        "# use the generator to generate n fake examples, with class labels\n",
        "def generate_test_samples(generator, latent_dim, test_samples):\n",
        "  # generate points in latent space\n",
        "  n_samples = opf_real_conditions.shape[0]\n",
        "  z_input, labels_input = generate_latent_points(latent_dim, n_samples)\n",
        "  # predict outputs\n",
        "  images = generator.predict([z_input, opf_real_conditions])\n",
        "  # create class labels\n",
        "  y = np.ones((n_samples, 1))\n",
        "  return opf_real_conditions,images, y\n",
        "\n",
        "def optimality_checking(p_opt,q_opt,p_fake,q_fake):\n",
        "  #pdb.set_trace()\n",
        "  p_mse = K.sum(K.square(p_opt*100-p_fake*100))\n",
        "  q_mse = K.sum(K.square(q_opt*100-q_fake*100))\n",
        "  return p_mse,q_mse\n",
        "\n",
        "def financial_optimality_checking(p_opt,q_opt,p_fake,q_fake):\n",
        "  #pdb.set_trace()\n",
        "  p_opt_actual = tf.convert_to_tensor(p_opt*100,dtype=tf.float32)\n",
        "  p_fake_actual = tf.convert_to_tensor(p_fake*100,dtype=tf.float32)\n",
        "  #pdb.set_trace()\n",
        "  p_opt_actual_cost = K.sum(tf.math.multiply(p_opt_actual, tf_c1)+\\\n",
        "                              tf.math.multiply(K.square(p_opt_actual), tf_c2))\n",
        "  p_fake_actual_cost = K.sum(tf.math.multiply(p_fake_actual, tf_c1)+\\\n",
        "                            tf.math.multiply(K.square(p_fake_actual), tf_c2))\n",
        "  p_mse = K.sum(p_opt_actual_cost-p_fake_actual_cost)\n",
        "  print(p_opt_actual_cost)\n",
        "  print(p_fake_actual_cost)\n",
        "  print(p_mse)\n",
        "  return p_mse\n",
        "\n",
        "\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "  # generate points in the latent space\n",
        "  code_input = np.random.uniform(-1,-0.6,n_samples).reshape([n_samples,1])\n",
        "  x_input = randn(latent_dim * n_samples)\n",
        "  z_input = x_input.reshape(n_samples, latent_dim)\n",
        "  # generate labels\n",
        "  p_demand,q_demand = rdm_load_pq_20per(case118_pload,case118_qload,n_samples,wind_der_ids,solar_der_ids)\n",
        "  labels = np.concatenate([p_demand,q_demand],axis=1)\n",
        "  return [code_input,z_input, labels]\n",
        "\n",
        "def rdm_load_pq_20per(case_pload,case_qload,sample_number,wind_der_ids,solar_der_ids):\n",
        "    #pdb.set_trace()\n",
        "    wind_sum=0\n",
        "    solar_sum=0\n",
        "    number_of_bus = case_pload.shape[0]\n",
        "    p_demand = np.zeros([sample_number,number_of_bus])\n",
        "    q_demand = np.zeros([sample_number,number_of_bus])\n",
        "    for i in range(0,number_of_bus):\n",
        "        if case_pload[i]!=0:\n",
        "          pi = case_pload[i]\n",
        "          qi = case_qload[i]\n",
        "          p_mw = np.random.uniform(pi*0.8,pi*1.2,sample_number)\n",
        "          q_mvar = np.random.uniform(qi*0.8,qi*1.2,sample_number)\n",
        "          p_demand[:,i] = p_mw\n",
        "          q_demand[:,i] = q_mvar\n",
        "          der_i=0\n",
        "        if i in wind_der_ids:\n",
        "          #for each wind farm, there are 6 wind turbines\n",
        "          der_i = draw_wind_generation(1,2,5,sample_number)\n",
        "          wind_sum=wind_sum+np.mean(der_i)\n",
        "        elif i in solar_der_ids:\n",
        "          #for each PV generator, there are 3000 panels\n",
        "          der_i = draw_PV_generation(10000,2,5,sample_number)\n",
        "          solar_sum=solar_sum+np.mean(der_i)\n",
        "        p_demand[:,i] = p_demand[:,i]-der_i\n",
        "    #print(wind_sum)\n",
        "    #print(solar_sum)\n",
        "    return p_demand,q_demand\n",
        "\n",
        "def rdm_gen_pv(p_min,p_max,sample_number):\n",
        "  #pdb.set_trace()\n",
        "  number_of_gen = p_min.shape[0]\n",
        "  p_supply = np.zeros([sample_number,number_of_gen])\n",
        "  for i in range(0,number_of_gen):\n",
        "    #if mat_gen['gen118'][i,1]!=0:\n",
        "    p_gen = np.random.uniform(p_min[i],p_max[i],sample_number)\n",
        "    p_supply[:,i] = p_gen\n",
        "  ###\n",
        "  hard_clip_min = 0.96\n",
        "  hard_clip_max = 1.06\n",
        "  _mean=1\n",
        "  _std=0.01\n",
        "  a = (hard_clip_min - _mean) / _std\n",
        "  b = (hard_clip_max - _mean) / _std\n",
        "\n",
        "  result = truncnorm.rvs(a=a, b=b, loc=_mean,size=sample_number*(number_of_gen-1),scale=_std)\n",
        "  ###\n",
        "  vm_gen = result.reshape([sample_number,number_of_gen-1])\n",
        "  #np.random.uniform(0.94,1.06,[sample_number,number_of_gen-1])\n",
        "  return p_supply,vm_gen\n",
        "\n",
        "def rdm_gen_pv_low(p_min,p_max,sample_number,mat_gencost):\n",
        "  #pdb.set_trace()\n",
        "  number_of_gen = p_min.shape[0]\n",
        "  p_supply = np.zeros([sample_number,number_of_gen])\n",
        "  for i in range(0,number_of_gen):\n",
        "    if mat_gencost[i,5]==20 and mat_gencost[i,4]<=0.1:\n",
        "      p_gen = np.random.uniform(p_min[i],p_max[i],sample_number)\n",
        "      p_supply[:,i] = p_gen\n",
        "  vm_gen = np.random.uniform(0.94,1.06,[sample_number,number_of_gen-1])\n",
        "  return p_supply,vm_gen\n",
        "\n",
        "def draw_wind_generation(number_of_turbines, k,c,sample_number):\n",
        "  x = weibull_min.rvs(k, loc=0, scale=c, size=sample_number)\n",
        "  p=0.5*1.25*np.power(x,3)*1800/1000000\n",
        "  return p*number_of_turbines\n",
        "\n",
        "def draw_PV_generation(number_of_panels,k,c,sample_number):\n",
        "  x = weibull_min.rvs(k, loc=0, scale=c, size=sample_number)\n",
        "  return x*number_of_panels/1000000\n",
        "\n",
        "# define the combined generator and discriminator model, for updating the generator\n",
        "def define_gan(g_model, d_model):\n",
        "  # make weights in the discriminator not trainable\n",
        "  d_model.trainable = False\n",
        "  [g_active,g_reactive,bus_vm,bus_va] = generator.output\n",
        "  [gen_code, gen_noise, gen_label] = generator.input\n",
        "  gan_output = d_model([tf.reshape(gen_label,[-1,1,118*2]),tf.reshape(g_active,[-1,1,118]),\\\n",
        "                        tf.reshape(g_reactive,[-1,1,118]),tf.reshape(bus_vm,[-1,1,118]),\\\n",
        "                        tf.reshape(bus_va,[-1,1,118])])\n",
        "  # define gan model as taking noise and label and outputting a classification\n",
        "  model = Model([gen_code, gen_noise, gen_label], gan_output)\n",
        "  return model\n",
        "\n",
        "def feasibility_checking(p_demand,q_demand, active_p,reactive_q,vm,va):\n",
        "  #pdb.set_trace()\n",
        "  generated_size = p_demand.shape[0]\n",
        "  #Step1: calculate power withdraw on each bus\n",
        "  P_out = tf.convert_to_tensor(p_demand-active_p,dtype='float32')\n",
        "  Q_out = tf.convert_to_tensor(q_demand-reactive_q,dtype='float32')\n",
        "  #pdb.set_trace()\n",
        "  #get voltage on each bus\n",
        "  v_r = tf.math.multiply(vm,tf.cos(tf.math.multiply(va,tf.constant(math.pi/180,dtype='float32'))))\n",
        "  v_i = tf.math.multiply(vm,tf.sin(tf.math.multiply(va,tf.constant(math.pi/180,dtype='float32'))))\n",
        "  V = tf.reshape(tf.complex(v_r,v_i),[generated_size,118])\n",
        "\n",
        "  #calculate current\n",
        "  Y_bus_tf = tf.convert_to_tensor(Y_bus)\n",
        "  I = tf.matmul(V,Y_bus_tf)\n",
        "\n",
        "  #calculate power injection on each bus\n",
        "  S_in = tf.math.multiply(V,tf.math.conj(I))\n",
        "  P_in = tf.math.real(S_in)\n",
        "  Q_in = tf.math.imag(S_in)\n",
        "\n",
        "  #evaluate the balance\n",
        "  p_balance = tf.reduce_mean(P_in+P_out,axis=0)\n",
        "  q_balance = tf.reduce_mean(Q_in+Q_out,axis=0)\n",
        "  return p_balance,q_balance\n",
        "\n",
        "def get_variation_cost(deltaP,mat_gen,mat_gencost):\n",
        "  p_gr = mat_gen[:,8]\n",
        "  c1 = mat_gencost[:,5]\n",
        "  c2 = mat_gencost[:,4]\n",
        "  sr=100\n",
        "  rui = (3/60)/(p_gr/sr)\n",
        "  delta_pi = (sr/rui)/(np.sum(sr/rui))*deltaP\n",
        "  cost = (delta_pi*100)*c1+np.square((delta_pi*100))*c2\n",
        "  return np.sum(cost)\n",
        "\n",
        "def get_pq_bound(number_of_buses, mat_gen):\n",
        "  number_of_gens = mat_gen.shape[0]\n",
        "  p_upper = np.zeros(number_of_buses)\n",
        "  q_upper = np.zeros(number_of_buses)\n",
        "  q_lower = np.zeros(number_of_buses)\n",
        "  j=0\n",
        "  for i in range(0,number_of_buses):\n",
        "    if i in (mat_gen[:,0]-1):\n",
        "      #pdb.set_trace()\n",
        "      p_upper[i]=mat_gen[j,8]\n",
        "      q_upper[i]=mat_gen[j,3]\n",
        "      q_lower[i]=mat_gen[j,4]\n",
        "      j=j+1\n",
        "  tf_p_upper = tf.convert_to_tensor(p_upper/baseMVA,dtype='float32')\n",
        "  tf_q_upper = tf.convert_to_tensor(q_upper/baseMVA,dtype='float32')\n",
        "  tf_q_lower = tf.convert_to_tensor(q_lower/baseMVA,dtype='float32')\n",
        "  return tf_p_upper,tf_q_upper,tf_q_lower\n",
        "\n",
        "def replacenan(t):\n",
        "    return tf.where(tf.math.is_nan(t), tf.zeros_like(t), t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeNVfIwlqED3"
      },
      "outputs": [],
      "source": [
        "latent_dim = 200\n",
        "discriminator = load_model('opf_gan/d.h5')\n",
        "generator = load_model('opf_gan/g.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ABp6_U8OOzq"
      },
      "outputs": [],
      "source": [
        "number=0\n",
        "x = np.arange(-1,1,0.01)\n",
        "z = np.zeros([200])\n",
        "c = np.zeros([200])\n",
        "tf_c1,tf_c2=get_gencost(118,mat_gen,mat_gencost)\n",
        "c_input, z_input, labels_input = generate_latent_points(latent_dim, 1)\n",
        "for i in range(0,200):\n",
        "    c_input[0,0]=x[i]\n",
        "    images = generator.predict([c_input.reshape([-1,1,1]),z_input.reshape([-1,1,latent_dim]),\\\n",
        "                                opf_real_conditions[number,:].reshape([1,1,236])])\n",
        "    op=financial_optimality_checking(opf_real_p[number,:],opf_real_q[number,:],images[0],images[1])\n",
        "    z[i]=op\n",
        "    cost1=tf.math.multiply(images[0]*100, tf_c1)\n",
        "    cost2=tf.math.multiply(K.square(images[0]*100), tf_c2)\n",
        "    print(1)\n",
        "    print(tf.reduce_sum(cost2))\n",
        "    suma = tf.reduce_sum(cost1+cost2,axis=1)\n",
        "    c[i]=suma\n",
        "    print(str(i))\n",
        "plt.plot(c[:])\n",
        "plt.xlabel('Value of the Latent Code')\n",
        "plt.ylabel('Cost Value')\n",
        "plt.xticks(np.arange(0, 200, 20), np.arange(-10, 10, 2)/10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6o1zb5eInSe5"
      },
      "outputs": [],
      "source": [
        "#Batch generation with Zero Order Optimization\n",
        "tf_p_upper,tf_q_upper,tf_q_lower = get_pq_bound(118, mat_gen)\n",
        "loss_acc = 0\n",
        "loss_acc_list=[]\n",
        "loss_per_list=[]\n",
        "sdp_list = []\n",
        "gan_list = []\n",
        "feasibility_store_list=[]\n",
        "actual_cost = []\n",
        "gan_cost = []\n",
        "demand_list = []\n",
        "solutionp_list = []\n",
        "solutionv_list = []\n",
        "#Sample numeber\n",
        "sample_batch = 50 #100,200,500,1000,5000\n",
        "#Cost coefficients\n",
        "tf_c1,tf_c2=get_gencost(118,mat_gen,mat_gencost)\n",
        "#for 1000 test cases\n",
        "for test_iter in range(0,1000):\n",
        "  p_opt_actual = tf.convert_to_tensor(opf_real_p[test_iter,:]*100,dtype=tf.float32)\n",
        "  cost1=tf.math.multiply(p_opt_actual, tf_c1)\n",
        "  cost2=tf.math.multiply(K.square(p_opt_actual), tf_c2)\n",
        "  suma = tf.reduce_sum(cost1+cost2)\n",
        "  k=0\n",
        "  number=test_iter\n",
        "  #Generate latent points\n",
        "  c_input, z_input, _ = generate_latent_points(latent_dim, sample_batch)\n",
        "  tf_z=tf.convert_to_tensor(z_input.reshape([sample_batch,1,latent_dim]))\n",
        "  images = generator.predict([c_input.reshape([-1,1,1]),tf_z,np.repeat(opf_real_conditions[number,:].reshape([-1,1,236]),sample_batch,axis=0)])\n",
        "  y_a= K.sum(tf.math.multiply(images[0]*100, tf_c1)+tf.math.multiply(K.square(images[0]*100), tf_c2),axis=1)\n",
        "  solutions = images[0]\n",
        "  _,score,score2 = discriminator([np.repeat(opf_real_conditions[number,0:118*2].reshape([-1,1,118*2]),sample_batch,axis=0),\\\n",
        "                                          tf.reshape(images[0],[-1,1,118]),\\\n",
        "                                          tf.reshape(images[1],[-1,1,118]),\\\n",
        "                                          tf.reshape(images[2],[-1,1,118]),\\\n",
        "                                          tf.reshape(images[3],[-1,1,118])])\n",
        "  candidates =y_a.numpy()\n",
        "  best_index = np.argmin(score+score2*0.5)\n",
        "  best_score1 = score[best_index]\n",
        "  best_score2 = score2[best_index]\n",
        "  P = images[0]\n",
        "  tf_p = images[0]\n",
        "  tf_q = images[1]\n",
        "  tf_v = images[2]\n",
        "  tf_phi = images[3]\n",
        "  best_p = tf.reshape(tf_p[best_index],[-1,1,118])\n",
        "  best_q = tf.reshape(tf_q[best_index],[-1,1,118])\n",
        "  best_v = tf.reshape(tf_v[best_index],[-1,1,118])\n",
        "  best_phi = tf.reshape(tf_phi[best_index],[-1,1,118])\n",
        "  dual_v = np.zeros(1)\n",
        "  dual_beta = np.zeros([1,1,118])\n",
        "  dual_gamma = np.zeros([1,1,118])\n",
        "  dual_epsilon = np.zeros(1)\n",
        "  g_sign = np.zeros([1,1,118])\n",
        "  p_gradient = np.zeros([1,1,118])\n",
        "  update_dim = np.ones([1,1,118])\n",
        "  for l in range(0,5):\n",
        "    h=0.00000001\n",
        "    best_p = best_p-0.000000001*p_gradient*update_dim\n",
        "    best_p_plus = np.repeat(tf.reshape(best_p,[-1,1,118]),118,axis=0)+(np.identity(118)*basis_vector).reshape([-1,1,118])*h\n",
        "    best_p_minus = np.repeat(tf.reshape(best_p,[-1,1,118]),118,axis=0)-(np.identity(118)*basis_vector).reshape([-1,1,118])*h\n",
        "    _,score_plus,score_plus2 = discriminator([np.repeat(opf_real_conditions[number,0:118*2].reshape([-1,1,118*2]),118,axis=0),\\\n",
        "                            best_p_plus,np.repeat(tf.reshape(best_q,[-1,1,118]),118,axis=0),\\\n",
        "                            np.repeat(tf.reshape(best_v,[-1,1,118]),118,axis=0),\\\n",
        "                            np.repeat(tf.reshape(best_phi,[-1,1,118]),118,axis=0)])\n",
        "    _,score_minus,score_minus2 = discriminator([np.repeat(opf_real_conditions[number,0:118*2].reshape([-1,1,118*2]),118,axis=0),\\\n",
        "                            best_p_minus,np.repeat(tf.reshape(best_q,[-1,1,118]),118,axis=0),\\\n",
        "                            np.repeat(tf.reshape(best_v,[-1,1,118]),118,axis=0),\\\n",
        "                            np.repeat(tf.reshape(best_phi,[-1,1,118]),118,axis=0)])\n",
        "    dj = tf.reshape((score_plus-score_minus),[1, 1, 118])/(h*2)\n",
        "    dj2 = tf.reshape((score_plus2-score_minus2),[1, 1, 118])/(h*2)\n",
        "    p_gradient = 20000*tf.math.multiply(best_p, tf_c2)+tf_c1*100+dual_epsilon*dj2+dual_v*dj+dual_beta-dual_gamma\n",
        "    if l==0:\n",
        "      g_sign = np.sign(p_gradient)\n",
        "      np.place(g_sign, g_sign==0., 2)\n",
        "    if np.all(np.sign(p_gradient)!=g_sign):\n",
        "      break\n",
        "    else:\n",
        "      update_dim = np.sign(p_gradient)==g_sign\n",
        "      print(np.sum(update_dim))\n",
        "    best_p = tf.math.minimum(tf.math.maximum(best_p,tf.zeros([1,1,118])),tf.reshape(tf_p_upper,[1,1,118]))\n",
        "    lagrangian = tf.reduce_sum(tf.math.multiply(best_p*100, tf_c1)+tf.math.multiply(K.square(best_p*100), tf_c2)+\\\n",
        "        dual_v*best_score1+dual_beta*(best_p-tf_p_upper)-dual_gamma*best_p+dual_epsilon*best_score2)\n",
        "    dual_v = dual_v+lagrangian/best_score1\n",
        "    dual_epsilon = dual_v+lagrangian/best_score2\n",
        "    dual_beta = tf.nn.relu(dual_beta+replaceinf(replacenan(lagrangian/(best_p-tf_p_upper))))\n",
        "    dual_gamma = tf.nn.relu(dual_gamma+replaceinf(replacenan(lagrangian/(-best_p))))\n",
        "  cost1=tf.math.multiply(best_p*100, tf_c1)\n",
        "  cost2=tf.math.multiply(K.square(best_p*100), tf_c2)\n",
        "  suma1 = tf.reduce_sum(cost1+cost2)\n",
        "  end_time = datetime.datetime.now()\n",
        "  y_b=suma1\n",
        "  err = y_b-suma\n",
        "  err_rate = err/suma\n",
        "  loss_acc_list.append(err)\n",
        "  loss_per_list.append(err_rate)\n",
        "  sdp_list.append(suma)\n",
        "  gan_list.append(y_b)\n",
        "  _,aa,_=discriminator([opf_real_conditions[number,0:118*2].reshape([-1,1,118*2]),best_p,best_q,best_v,best_phi])\n",
        "  feasibility_store_list.append(aa)\n",
        "  demand_list.append(opf_real_conditions[number,:])\n",
        "  solutionp_list.append(images[0][np.argmin(score)])\n",
        "  solutionv_list.append(images[2][np.argmin(score)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jprKq0_c5hUJ"
      },
      "outputs": [],
      "source": [
        "mean_value = np.mean(np.absolute(loss_per_list))\n",
        "deviation = np.sqrt(np.sum(np.square(loss_per_list-mean_value))/len(loss_per_list)) \n",
        "print(np.mean(np.absolute(loss_per_list)))\n",
        "print(deviation*1.96/np.sqrt(len(loss_per_list)))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "OPF_test_grid118.ipynb",
      "provenance": [],
      "mount_file_id": "1aX1m26lVTj9jirdbJnOlsrnHs5Dk24Z3",
      "authorship_tag": "ABX9TyNc3CKhHBWS+7Pxlw5rBscb",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}